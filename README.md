# ğŸ—ï¸ SiteWatch AI â€” Construction Site Intelligence

> **The problem:** Construction site managers spend 30â€“45 minutes every morning manually cross-referencing weather apps, safety handbooks, and their own site plans to decide what their crew can actually do that day.
>
> **SiteWatch:** One question. Three sources looked up in parallel. One cited briefing.

---

## The Core Scenario

```
Site Manager: "Morning briefing for our Sydney site. Active works today:
               tower crane, concrete pour on level 4, glazing crew on facade."

SiteWatch:
  ğŸ§  Profile loaded â€” Site Manager, active works: crane / concrete / glazing
  ğŸ“– Searching handbook... 3 relevant sections found
  ğŸŒ¤ Fetching weather for Sydney, Australia...
  âš¡ Cross-referencing evidence...

  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  MORNING BRIEFING â€” Sydney Site

  Current conditions: 42 km/h wind, 21Â°C, 0 mm rain

  ğŸ›‘ Tower Crane: SUSPENDED
     Wind is 42 km/h. Handbook limit is 38 km/h â†’ exceeded [Source 1, chunk 2]
     Resume when sustained wind drops below 38 km/h.

  âœ… Concrete Pour (Level 4): GO
     Temperature 21Â°C â€” within the 10â€“32Â°C standard range [Source 1, chunk 4]
     Monitor curing temp every 2 hours.

  ğŸ›‘ Glazing / Facade: SUSPENDED
     Wind is 42 km/h. Glazing limit is 30 km/h (sail effect) [Source 2, chunk 1]
     Redeploy crew to interior works.

  Overall Site Risk: HIGH â€” Site Manager + Safety Officer sign-off required
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

This answer required three things simultaneously:
- **Memory** â†’ who is the user, what are the active work packages
- **RAG** â†’ exact thresholds from the handbook, with citations
- **Weather** â†’ actual conditions for the specified location right now

None of the three is useful alone. The product value is the synthesis.

---

## How the Three Features Connect

The key architectural piece is the **evidence bag** pattern. Rather than chaining
features sequentially, all three sources are gathered into a `FusionResult` object
**before** any LLM synthesis happens. The synthesis prompt can only reference what's
in the bag â€” it cannot reach outside it. This is what makes citations honest.

```
query("Morning briefing for Sydney site")
         â”‚
         â”œâ”€â”€ _extract_location()       â†’  "Sydney, Australia"
         â”‚                                (fast LLM call, ~0.2s)
         â”‚
         â”‚   [ThreadPoolExecutor â€” run in parallel]
         â”œâ”€â”€ _gather_rag()             â†’  FusionResult.rag_context
         â”‚   hybrid_search â†’ RRF                            (run concurrently)
         â”‚   build_context_block
         â”‚
         â””â”€â”€ _gather_weather()         â†’  FusionResult.weather_conditions
             geocode â†’ archive API                         (run concurrently)
             sandbox analysis
             condense to bullet points

         â†“   [Memory â€” fast local file read, sequential]
         â””â”€â”€ build_memory_context()    â†’  FusionResult.user_context

         â†“   [Single synthesis LLM call â€” reads evidence bag only]
         _build_messages(FusionResult)
         llm.stream()                  â†’  tokens streamed to UI

         â†“   [Post-processing]
         validate_citations()          â†’  strips hallucinated [Source N] refs
         _parse_risk_level()           â†’  LOW / MEDIUM / HIGH / CRITICAL
         maybe_write_memory()          â†’  writes if high-signal fact found
```

Total latency â‰ˆ `max(rag_time, weather_time) + synthesis_time` â€” not their sum.

---

## Quickstart

```bash
# 1. Set up
cp .env.example .env # add your GROQ_API_KEY (free at console.groq.com)
make install

# 2. Run
make web                       # opens at localhost:8501

# 3. Demo flow (takes ~3 minutes)
#    a. Upload sample_docs/sitewatch_handbook.txt in the sidebar
#    b. Tell SiteWatch your role:
#       "I'm the site manager. Active works: crane, concrete pour on level 4,
#        glazing crew on the facade."
#    c. Ask: "Give me my morning briefing for the Sydney CBD site."
#    d. Watch: three evidence sources appear as they load, then a cited briefing
```

---

## Make Commands

| Command | What it does |
|---|---|
| `make web` | Start the SiteWatch web UI |
| `make cli` | Terminal interface |
| `make sanity` | End-to-end integration test â†’ `artifacts/sanity_output.json` |
| `make eval` | 10-question evaluation harness â†’ `artifacts/eval_report.json` |
| `make install` | Install all dependencies |
| `make clean` | Remove ChromaDB + artifacts |

---

## Safety Guarantees

Every answer from documents is grounded and verifiable:

| Property | How it works |
|---|---|
| **No hallucinated citations** | Post-generation validator strips `[Source N]` refs exceeding the retrieved chunk count |
| **Explicit threshold comparison** | System prompt requires format: *"Wind is X km/h. Limit is Y km/h â†’ exceeded."* |
| **Retrieval failure discipline** | Score floor of 0.005 on RRF fusion; `NO_DOCS_PROMPT` template when no chunks pass |
| **Injection resistance** | Document context wrapped in boundary markers; 11-pattern regex scanner fires pre-LLM |
| **Memory discipline** | Two-stage pipeline: LLM evaluation (confidence â‰¥ 0.65) + semantic dedup before any write |
| **Sandbox isolation** | subprocess + TemporaryDirectory + stripped env + 15s timeout |

---

## Project Layout

```
app/
â”œâ”€â”€ intelligence.py      â† SiteWatch fusion core (the product)
â”œâ”€â”€ router.py            â† Intent classification
â”œâ”€â”€ chatbot.py           â† General-purpose chatbot
â”œâ”€â”€ config.py            â† All constants
â”œâ”€â”€ llm/client.py        â† Groq wrapper + streaming
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ ingestion.py     â† Parse â†’ Chunk â†’ Embed â†’ Index
â”‚   â”œâ”€â”€ retrieval.py     â† BM25 + Dense + RRF + threshold filter
â”‚   â”œâ”€â”€ grounding.py     â† Citation hallucination validator
â”‚   â””â”€â”€ file_manager.py  â† List / delete / inspect / reindex
â”œâ”€â”€ memory/
â”‚   â””â”€â”€ memory_manager.py â† Evaluate â†’ Dedup â†’ Write
â””â”€â”€ sandbox/
    â””â”€â”€ executor.py      â† Open-Meteo fetch + subprocess sandbox

web_app.py               â† SiteWatch UI (streaming, risk banners, evidence pills)
cli.py                   â† Terminal interface
scripts/
â”œâ”€â”€ eval_harness.py      â† Automated evaluation (10 test cases, 4 categories)
â”œâ”€â”€ run_sanity.py        â† End-to-end integration test
â””â”€â”€ verify_output.py     â† Validates sanity_output.json

sample_docs/
â”œâ”€â”€ sitewatch_handbook.txt  â† Construction safety thresholds (primary demo doc)
â”œâ”€â”€ sample.txt              â† General document for RAG evaluation
â””â”€â”€ injection_test.txt      â† Prompt injection resistance test

```
---
## Participant Info

- **Name**: Sai Ganesh Voodi
- **Email**: saiganeshvoodi@gmail.com
- **GitHub Username**: https://github.com/saihub404
- **Video Walkthrough**: https://youtu.be/p-xiS6NN4_c

---

## Architecture

See [ARCHITECTURE.md](ARCHITECTURE.md) for the full design overview including diagrams.

---

## Evaluation Questions

See [EVAL_QUESTIONS.md](EVAL_QUESTIONS.md) for suggested test questions covering all features.